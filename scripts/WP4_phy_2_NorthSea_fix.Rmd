---
title: "WP4_phy_NorthSea_fix.Rmd"
author: "Luuk van der Heijden"
date: "15 june 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Global options

```{r global_options, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

require(robis)
require(lubridate)
require(tidyverse)

```

# Here we load the data that has been extracted from the OBIS server. 

In the next step of the analysis, we filter out all datasets that have species known to be phytoplankton, thus excluding the seaweeds etc from the phylum that we chose in the previous section. We make a list of these data sets, check for the largest which with we start. Then we look up their metadata and store this information in a .csv file. We determine their number of unique phytoplankton species.

In a manual selection step, we fill a field called 'include' to determine what datasets we are going to use in subsequent analysis. We re-read the .csv file and use it to collect the final set of records to be used. We store these records in a binary file.


```{r manipulating of datasets, warning = FALSE, echo = FALSE}

# #############################################################################
# Load these records with data
# #############################################################################
all2Data <- read_delim(file.path("../data/derived_data/all2Data.csv"), delim = ";")

# Use phyla that are associated with phytoplankton
#non_phy_data <- all2Data %>%
#  filter(!phylum %in% c("Cyanobacteria", "Bigyra", "Cercozoa", "Ciliophora", "Cryptophyta", "Foraminifera", "Haptophyta", "Heliozoa", "Myzozoa",
#                        "Ochrophyta", "Oomycota", "Radiozoa", "Chlorophyta", "Choanozoa", "Euglenozoa", NA))

# Distinct species in phy_data
#non_phy_spec <- non_phy_data %>%
#  distinct(scientificnameaccepted, .keep_all = TRUE) %>%
#  select(scientificnameaccepted, phylum, scientificnameauthorship)

#write.csv(non_phy_spec, file.path("../data/derived_data/non_phy_spec.csv"), row.names = FALSE)

# Use phyla that are associated with phytoplankton and that don't go up to genus / species level
phy_data <- all2Data %>%
  filter(phylum %in% c("Cyanobacteria", "Bigyra", "Cercozoa", "Ciliophora", "Cryptophyta", "Foraminifera", "Haptophyta", "Heliozoa", "Myzozoa", "Ochrophyta", "Oomycota", "Radiozoa", "Chlorophyta", "Choanozoa", "Euglenozoa", NA)) %>%
  filter(!genus %in% NA)  

# Distinct species in phy_data
phy_spec <- phy_data %>%
  distinct(scientificnameaccepted, .keep_all = TRUE) %>%
  select(scientificnameaccepted, aphiaidaccepted, phylum, scientificnameauthorship) 

# Load the file including scientificnames that have the trait "phytoplankton" assigned
phy_spec_trait <- read_delim(file.path("../data/derived_data/phy_spec_traits.csv"), delim = ";")

# Join these two species files, so that we have the traits from Worms in our species list
phy_spec_new <- phy_spec %>%
  left_join(., phy_spec_trait, by = "scientificnameaccepted")

# Write csv
write.csv(phy_spec_new, file.path("../data/derived_data/phy_spec_new.csv"), row.names = FALSE)

# Exclude the species that are not phytoplankton, they are summed in this list. This is specific for the North Sea:
phy_corrected <- read_delim(file.path("../data/derived_data/phy_spec_new_corrected.csv"), delim = ";")

# This file contains several traits, i.e. 
# "phytoplankton" (which came from the WORMS traits)
# "phy" (assigned based on experience), 
# "cyano" (for cyanobacteria, 
# "foram" (for foraminifera) and 
# "not" (when they are NOT phytoplankton). 
# We use
phy_traits_used <- c("phytoplankton", "phy", "cyano")

# Select phytoplankton only in this file
phy_spec_used <- phy_corrected %>%
  filter(trait %in% phy_traits_used)

# #############################################################################
# Here we do the first cleaning of the datasets
# 1. We exclude non-phytoplankton species that have been selected manually for our dataset (see file uploaded above)
# #############################################################################
clean_phy <- phy_data %>% 
  filter(scientificnameaccepted %in% phy_spec_used$scientificnameaccepted)    # Exclude non-phytoplankton

```

## Here we do some manual repairs on datasets that are still not usable. 

```{r fix a number of datasets, warning = FALSE, echo = FALSE}
# Incl a file that contains the datasets and the short abbr of dataset (created manually)
datasets_modified <- read_delim(file.path("../data/derived_data/allDatasets_modified_2020-06-22.csv"), delim = ";") %>%
  rename(datasetID = datasetid)

# Join the datasetnames and abbreviations to the main df
clean_phy <- clean_phy %>%
  left_join(., datasets_modified, by = "datasetID")

# Merge the Sylt Romo datasets
clean_phy <- clean_phy %>%
  filter(!grepl('Sylt_Road', collectioncode)) %>%                                                     # Here we merge and fix the Sylt-Romo datasets
    bind_rows(clean_phy %>%
      filter(grepl('Sylt_Road', collectioncode)) %>%   
        mutate(datasetID = 5451)) 

# #############################################################################
# Here we do some manual repairs on datasets that are still not usable, we fix:
# Fill in missing eventID's with date and location 
# Extract the aphiaid from aphiaidaccepted
# Duplicates that occurred due to two sample moments on one day
# #############################################################################
fix_phy <- clean_phy %>%
  distinct(aphiaidaccepted, datasetid, datecollected, decimallatitude, decimallongitude, .keep_all = TRUE) %>%       # Select distinct objects
  filter(!datecollected %in% NA) %>%                                                                                 # Remove obs. without date (9)
  mutate(date = as.Date.POSIXct(datecollected)) %>%                                                                  # Make sure all dates are in one format
  mutate(month = lubridate::month(datecollected)) %>%                                                                # Create column with months
  mutate(year = lubridate::year(datecollected)) %>%                                                                  # Create column with years
  mutate(datasetID = as.numeric(datasetID)) %>%                                                                      # Make numeric
  unite(eventID_2, c("datecollected", "decimallatitude", "decimallongitude"), sep = "-", remove = FALSE) %>%         # Make eventID were not present
  mutate(eventIDnew = ifelse(is.na(eventid), eventID_2, eventid)) %>%
  mutate(aphiaid_new = str_extract(aphiaidaccepted, "[^http://marinespecies.org/aphia.php?p=taxdetails&id=]+$")) %>% # Remove website from aphiaid
  select(-eventid, -eventID_2, -coordinateuncertaintyinmeters, -aphiaidaccepted, -aphiaid) %>%                       # Remove columns not necessary
  rename(eventid = eventIDnew, aphiaid = aphiaid_new)                                                             # Rename these columns created

# Save file
save(fix_phy, file = "../data/derived_data/fix_phy.Rdata")

```

## Reproducibility

```{r reproducibility}
# Date time
Sys.time()

# Here we store the session info for this script
sessioninfo::session_info()

# repository
git2r::repository()

```

